{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca968d90",
   "metadata": {},
   "source": "# Introduction to Computer Vision with OpenCV, YOLOv11, and Stable Diffusion"
  },
  {
   "cell_type": "markdown",
   "id": "5f9c97c2",
   "metadata": {},
   "source": [
    "\n",
    "## Objectives\n",
    "\n",
    "- Understand the basics of OpenCV and image handling in Python  \n",
    "- Apply common image filters with OpenCV  \n",
    "- Perform real‑time object detection with **YOLOv11**  \n",
    "- Generate images from text prompts using **Stable Diffusion 3** via the **Diffusers** library  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa07d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 🛠️ Setup (uncomment to run in a fresh environment)\n",
    "# Note: A CUDA‑enabled GPU is strongly recommended for YOLOv11 and Stable Diffusion.\n",
    "# !pip install opencv-python ultralytics diffusers transformers accelerate torch torchvision matplotlib pillow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c954e46a",
   "metadata": {},
   "source": [
    "## 1. Basic Introduction to OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601d700",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an example image\n",
    "img = cv2.imread('sample.jpg')  # ⬅️ Replace with your own image path\n",
    "if img is None:\n",
    "    raise FileNotFoundError(\"Please place an image named 'sample.jpg' in the notebook directory or edit the path.\")\n",
    "\n",
    "# Convert BGR (OpenCV default) to RGB for Matplotlib\n",
    "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_rgb)\n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179208ce",
   "metadata": {},
   "source": [
    "OpenCV loads images in **BGR** order. We converted to **RGB** here so the colors display correctly in Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1bf53d",
   "metadata": {},
   "source": [
    "## 2. Image Filtering with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6962c3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply common filters\n",
    "gray   = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "blur   = cv2.GaussianBlur(img_rgb, (5, 5), 0)\n",
    "median = cv2.medianBlur(img_rgb, 5)\n",
    "edges  = cv2.Canny(img, 100, 200)\n",
    "\n",
    "# Display results\n",
    "fig, ax = plt.subplots(2, 2, figsize=(10, 8))\n",
    "ax[0, 0].imshow(gray, cmap='gray');  ax[0, 0].set_title('Grayscale');     ax[0, 0].axis('off')\n",
    "ax[0, 1].imshow(blur);              ax[0, 1].set_title('Gaussian Blur'); ax[0, 1].axis('off')\n",
    "ax[1, 0].imshow(median);            ax[1, 0].set_title('Median Blur');    ax[1, 0].axis('off')\n",
    "ax[1, 1].imshow(edges, cmap='gray');ax[1, 1].set_title('Canny Edges');    ax[1, 1].axis('off')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dae15",
   "metadata": {},
   "source": [
    "The filters above demonstrate noise reduction (`GaussianBlur`, `medianBlur`) and edge detection (`Canny`). Experiment with kernel sizes and thresholds!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f446d148",
   "metadata": {},
   "source": [
    "## 3. Object Detection with YOLOv11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431b5006",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv11n model (nano variant for speed)\n",
    "model = YOLO('yolov11n.pt')  # Automatically downloads weights the first time\n",
    "\n",
    "results = model('sample.jpg')  # Path to image or list/ndarray\n",
    "results[0].show()  # In notebooks this displays inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df30b14",
   "metadata": {},
   "source": [
    "\n",
    "* `results` contains predicted bounding boxes, confidence scores, and class labels.  \n",
    "* Try different model variants like `yolov11s.pt`, `yolov11m.pt`, or the high‑accuracy `yolov11x.pt`.  \n",
    "* To run on video streams, simply pass a video file path or a webcam index (e.g., `0`) to `model()`.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11e2eea",
   "metadata": {},
   "source": [
    "## 4. Text‑to‑Image Generation with Stable Diffusion 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f46b531",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "from diffusers import StableDiffusionPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    'stabilityai/stable-diffusion-3-base',\n",
    "    torch_dtype=torch.float16 if device == 'cuda' else torch.float32\n",
    ").to(device)\n",
    "\n",
    "prompt = \"A futuristic cityscape at dusk, cinematic, ultra realistic\"\n",
    "image = pipe(prompt, num_inference_steps=30, guidance_scale=8.0).images[0]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(prompt)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718c45f6",
   "metadata": {},
   "source": [
    "\n",
    "> **Tip:** For lower‑memory GPUs you can enable *memory‑efficient attention* with `pipe.enable_model_cpu_offload()` or use a quantized checkpoint such as **SD3‑Medium‑Turbo**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18266fe2",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Next Steps\n",
    "\n",
    "- Fine‑tune **YOLOv11** on your own dataset with `model.train(data='data.yaml')`  \n",
    "- Experiment with different Stable Diffusion models (`sd3.5`, `sdxl`) and creative prompts  \n",
    "- Combine detection and generation: detect objects, then inpaint or replace them with Stable Diffusion!  \n",
    "\n",
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "- [Ultralytics YOLOv11 Documentation](https://docs.ultralytics.com/models/yolo11/)  \n",
    "- [Hugging Face **Diffusers** Library](https://github.com/huggingface/diffusers)  \n",
    "- [Stable Diffusion 3 Announcement](https://huggingface.co/blog/sd3)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
